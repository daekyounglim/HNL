{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Introduction ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 1. Scikit-learn basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 1. Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 3) (2,)\n",
      "(1, 3)\n"
     ]
    }
   ],
   "source": [
    "#Consider toy dataset\n",
    "X = np.array([[ 1,  2,  3], [11, 12, 13]])\n",
    "y = np.array([2.1, 11.9])\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "X_test =  np.array([[ 2, 3, 4]])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.08])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Init the model and set all the hyperparameters (if there are any)\n",
    "lr = LinearRegression()\n",
    "\n",
    "# Train the model\n",
    "lr.fit(X, y)\n",
    "# make a prediction\n",
    "lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 2. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Init, fit and transform\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1., -1., -1.],\n",
       "       [ 1.,  1.,  1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the same, but in 1 line\n",
    "scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.08])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "# create a pipeline\n",
    "pipeline = Pipeline([(\"scaler\", StandardScaler()), (\"lr\",LinearRegression())])\n",
    "# fit the whole pipeline\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# we can now use it like any other estimator and make a prediction\n",
    "pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.08])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init modela and transformer\n",
    "lr = LinearRegression()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit transformer\n",
    "scaler.fit(X)\n",
    "\n",
    "# Transform the data\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# Fit the model\n",
    "lr.fit(X_scaled, y)\n",
    "\n",
    "# Predict\n",
    "lr.predict(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 2. Using sklearn pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice  LotArea  OverallQual SaleCondition  YearBuilt\n",
       "0     208500     8450            7        Normal       2003\n",
       "1     181500     9600            6        Normal       1976\n",
       "2     223500    11250            7        Normal       2001\n",
       "3     140000     9550            7       Abnorml       1915\n",
       "4     250000    14260            8        Normal       2000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/house_prices_small.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1. Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "#### 1.1 explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice  LotArea  OverallQual SaleCondition  YearBuilt\n",
       "0     208500     8450            7        Normal       2003\n",
       "1     181500     9600            6        Normal       1976\n",
       "2     223500    11250            7        Normal       2001\n",
       "3     140000     9550            7       Abnorml       1915\n",
       "4     250000    14260            8        Normal       2000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice        0\n",
       "LotArea          0\n",
       "OverallQual      0\n",
       "SaleCondition    0\n",
       "YearBuilt        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Separate features form the target and perform train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tr, te = train_test_split(data)\n",
    "y_train = tr.SalePrice\n",
    "X_train = tr.drop([\"SalePrice\"], axis=1)\n",
    "\n",
    "y_test = te.SalePrice\n",
    "X_test = te.drop([\"SalePrice\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Encode categorical and ordinal features, scale numerical ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>YearBuilt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>7406</td>\n",
       "      <td>7</td>\n",
       "      <td>Partial</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>6171</td>\n",
       "      <td>6</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>3136</td>\n",
       "      <td>7</td>\n",
       "      <td>Normal</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>8120</td>\n",
       "      <td>4</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>7018</td>\n",
       "      <td>5</td>\n",
       "      <td>Alloca</td>\n",
       "      <td>1979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      LotArea  OverallQual SaleCondition  YearBuilt\n",
       "1021     7406            7       Partial       2006\n",
       "1399     6171            6        Normal       1925\n",
       "1251     3136            7        Normal       2003\n",
       "722      8120            4        Normal       1970\n",
       "894      7018            5        Alloca       1979"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to preprocess the features:\n",
    "\n",
    "- LotArea, YearBuilt - numerical features, scale\n",
    "- SaleCondition - categorical feature, one-hot encoding\n",
    "- OverallQual - ordinal feature, no need to encode\n",
    "- That being said, we need to apply different transformations to different columns. It can be done with ColumnTransformer:\n",
    "\n",
    "ColumnTransformer([\n",
    "    ('name1', transorm1, column_names1),\n",
    "    ('name2', transorm2, column_names2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "transformer = ColumnTransformer([\n",
    "    ('ohe', OneHotEncoder(), ['SaleCondition']),\n",
    "    ('scaling', StandardScaler(), ['LotArea', 'YearBuilt']),\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('col_transformer',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe', OneHotEncoder(),\n",
       "                                                  ['SaleCondition']),\n",
       "                                                 ('scaling', StandardScaler(),\n",
       "                                                  ['LotArea', 'YearBuilt'])])),\n",
       "                ('regression', LinearRegression())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('col_transformer', transformer),\n",
    "    ('regression', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Evaluate on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40605.6416762108"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "np.mean((y_pred - y_test)**2)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "np.mean((y_pred - y_test)**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Extract feature from texts and images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 8, 8)\n",
      "(1797, 64)\n",
      "(1797,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "print(digits['images'].shape)\n",
    "print(digits['data'].shape)\n",
    "print(digits['target'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.],\n",
       "       [ 0.,  0., 13., 15., 10., 15.,  5.,  0.],\n",
       "       [ 0.,  3., 15.,  2.,  0., 11.,  8.,  0.],\n",
       "       [ 0.,  4., 12.,  0.,  0.,  8.,  8.,  0.],\n",
       "       [ 0.,  5.,  8.,  0.,  0.,  9.,  8.,  0.],\n",
       "       [ 0.,  4., 11.,  0.,  1., 12.,  7.,  0.],\n",
       "       [ 0.,  2., 14.,  5., 10., 12.,  0.,  0.],\n",
       "       [ 0.,  0.,  6., 13., 10.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images contain 8x8 black'n'white pictures of hadwritten digits\n",
    "digits['images'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 15 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, axes = plt.subplots(3,5)\n",
    "axes = axes.flatten()\n",
    "for ax, image, label in zip(axes, digits['images'], digits['target']):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits['data'], digits['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()), ('clf', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('clf', KNeighborsClassifier()),\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Evaluate on test dataset¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def my_accuracy(true, predicted):\n",
    "    # your code here\n",
    "    return np.sum(true == predicted) / len(true)\n",
    "    \n",
    "# test that your function work the same as `accuracy_score` from sklearn\n",
    "my_accuracy(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part4. Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert documents to vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = \"This is my favourite movie\"\n",
    "d2 = \"Is this movie boring? Yes, it is!\"\n",
    "d3 = \"This is an exiting movie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['this', 'is', 'my', 'favourite', 'movie'],\n",
       " ['is', 'this', 'movie', 'boring', 'yes', 'it', 'is'],\n",
       " ['this', 'is', 'an', 'exiting', 'movie']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "D = [re.sub('[.!?,]', '', d.lower()).split(' ') for d in [d1, d2, d3]]\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['favourite', 'yes', 'my', 'movie', 'this', 'it', 'is', 'boring', 'an', 'exiting']\n"
     ]
    }
   ],
   "source": [
    "all_words = sum(D, [])\n",
    "V = list(set(all_words))\n",
    "print(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.zeros((len(D), len(V)))\n",
    "\n",
    "for j, v in enumerate(V):\n",
    "    for i , d in enumerate(D):\n",
    "        X[i,j] = sum([1 for w in d if w == v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1., 1., 1., 0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 1., 1., 1., 2., 1., 0., 0.],\n",
       "       [0., 0., 0., 1., 1., 0., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2. Tf-idf\n",
    "\n",
    "**Term Frequency times Inverce Document Frequency**\n",
    "\n",
    "A method to describe each document in the dataset with a vector of the same length. Takes into account, how often the word appears in the whole dataset.\n",
    "\n",
    "\n",
    "\n",
    "**Term frequency (tf)** - number of times a term occurs in a given document\n",
    "$$\n",
    "tf(t, d) = \\frac{\\# t \\text{ in } d}{len(d)}\n",
    "$$\n",
    "\n",
    "\n",
    "**Inverce document frequency (idf)** - measures informativeness of a term\n",
    "\n",
    "$$\n",
    "idf(t) = \\log \\frac{N}{(\\# d \\text{ with } t)} , N - \\text{ number of documents}\n",
    "$$\n",
    "\n",
    "If the word occures almost in all the documents (e.g. article, popular verb), then $idf$ will be very low.\n",
    "\n",
    "---\n",
    "Now we can covert each document onti the vector of size $M$:\n",
    "$$\n",
    "d \\rightarrow \\left(tf(t_1, d)\\cdot idf(t_1),\\,\\, \\dots, \\,\\, tf(t_M, d) \\cdot idf(t_M)\\right)\n",
    "$$\n",
    "\n",
    "\n",
    "---\n",
    "Let us calculate it for our simple example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2       , 0.        , 0.2       , 0.2       , 0.2       ,\n",
       "        0.        , 0.2       , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.14285714, 0.        , 0.14285714, 0.14285714,\n",
       "        0.14285714, 0.28571429, 0.14285714, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.2       , 0.2       ,\n",
       "        0.        , 0.2       , 0.        , 0.2       , 0.2       ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf\n",
    "tf = np.zeros((len(D), len(V)))\n",
    "\n",
    "for j, v in enumerate(V):\n",
    "    for i , d in enumerate(D):\n",
    "        tf[i,j] = sum([1 for w in d if w == v])/len(d)\n",
    "tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.09861229, 1.09861229, 1.09861229, 0.        , 0.        ,\n",
       "       1.09861229, 0.        , 1.09861229, 1.09861229, 1.09861229])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idf\n",
    "idf = np.zeros(len(V))\n",
    "\n",
    "for j, v in enumerate(V):\n",
    "    idf[j] = np.log(len(D)/ sum([1 for d in D if v in d]))\n",
    "\n",
    "idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22, 0.  , 0.22, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 0.16, 0.  , 0.  , 0.  , 0.16, 0.  , 0.16, 0.  , 0.  ],\n",
       "       [0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.22, 0.22]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf*idf\n",
    "np.round(X, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
